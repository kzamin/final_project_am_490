import os
import collections
import random
import pandas as pd
import json

from nltk.tokenize import word_tokenize
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer

from sklearn.naive_bayes import MultinomialNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier

from sklearn import metrics

'''
Related Work: 
http://cs229.stanford.edu/proj2013/ChaseGenainKarniolTambour-LearningMulti-LabelTopicClassificationofNewsArticles.pdf
https://www.kaggle.com/datasets/shivamkushwaha/bbc-full-text-document-classification
https://www.kaggle.com/datasets/therohk/million-headlines

Ideas: 
https://www.analyticsvidhya.com/blog/2021/12/text-classification-of-news-articles/
https://machinelearningmastery.com/gentle-introduction-bag-words-model/
https://www.datacamp.com/tutorial/naive-bayes-scikit-learn
'''

def demo():
    # business, tech, politics, sports, entertainment
    # {0: 'entertainment', 1: 'business', 2: 'sport', 3: 'politics', 4: 'tech'}
    dataset = "BBC News"
    vectorizers = [CountVectorizer(), TfidfVectorizer()]
    classifier, conversion = mnb_main(dataset, vectorizers[0])
    print(conversion)
    
    # generated by GPT-3
    articles = ["""The hometown heroes have done it again! Our local sports team has made it to the championship game, and the whole city is buzzing with excitement. 
    The team has been on a roll this season, with standout performances from key players. 
    The star quarterback has thrown touchdown after touchdown, while the running back has rushed for over 1,000 yards. 
    The defense has been strong all season, shutting down opposing teams and making big plays when it counts. 
    Now, they will face off against their toughest opponent yet in the championship game. The game is sure to be a nail-biter, with both teams bringing their A-game.""", 
    """New Movie from Acclaimed Director Set to Release Next Month. 
    Fans of award-winning director Martin Scorsese will be thrilled to hear that his latest movie, "The Irishman," is set to hit theaters next month.
    Based on the book "I Heard You Paint Houses" by Charles Brandt, "The Irishman" tells the story of Frank "The Irishman" Sheeran, a hitman who claimed to have carried out the infamous murder of Teamster leader Jimmy Hoffa. 
    The movie features an all-star cast, including Robert De Niro as Sheeran, Al Pacino as Hoffa, and Joe Pesci as Pennsylvania boss Russell Bufalino.""", 
    """New Smartphone Unveiled by Major Electronics Company. 
    A major electronics company has just unveiled their latest smartphone, and it's packed with impressive features. 
    The new device boasts a sleek design, a high-resolution display, and an advanced camera system. 
    One of the standout features of the new smartphone is its artificial intelligence-powered virtual assistant. 
    The assistant can understand and respond to natural language, making it easier for users to interact with their device. 
    It can also learn from the user's behavior and preferences, providing personalized recommendations and assistance.""", 
    """President Holds Press Conference to Address Recent Controversy.
    President Jane Doe held a press conference today to address the controversy surrounding her administration. 
    The president faced tough questions from reporters about allegations of corruption and abuse of power.
    The president began the conference by addressing the allegations head-on. 
    She denied any wrongdoing and asserted that her administration has been transparent and accountable. 
    She also pointed to the strong economy and low unemployment rate as evidence of her successful leadership.""", 
    """Major Corporation Announces Plans to Expand into New Market. A major corporation has announced plans to expand into a new market, in a move that is expected to boost the company's revenue and strengthen its global presence. 
    The corporation, which specializes in providing technology solutions for businesses, has been successful in its current market but is looking to diversify and reach a wider audience. 
    The new market offers a significant opportunity for growth, with a large potential customer base and a need for the company's services. 
    The expansion will involve the opening of a new office in the new market, as well as the hiring of local employees to serve the new customers. 
    The company will also be working closely with local partners and vendors to ensure a smooth transition and successful launch."""] 

    labels = [2, 0, 4, 3, 1]
    x = articles
    y = labels
    v = vectorizers[0]
    n = len(x)
    x_test = v.transform(x)
    y_pred = classifier.predict(x_test)
    for i, pred in enumerate(y_pred):
        print(f"Article: {articles[i][:50]}, Prediction: {conversion[pred]}")
    print("Accuracy:", metrics.accuracy_score(y, y_pred))

def main():
    datasets = ["BBC News", "Huffington Post [1 million]"]
    vectorizers = [CountVectorizer(), TfidfVectorizer()]
    print()
    for dataset in datasets[1:]:
        for v in vectorizers:
            print(f"Dataset: {dataset}, Vectorizer: {v}")
            print()
            knn_main(dataset, v)
            print()
            mnb_main(dataset, v)
            print()
            rand_forest_main(dataset, v)
            print()
            rnn_main(dataset, v) 
            print()
            dt_main(dataset, v) 
            print()
            print()
        print()

def mnb_main(dataset, v):
    if dataset == "BBC News":
        train_x, train_y, test_x, test_y, conversion = build_sets_bbc()
    elif dataset == "Huffington Post [1 million]":
        train_x, train_y, test_x, test_y, conversion = build_sets_huff()
    else:
        print(f"nb err: {dataset}")
        return 
    train_x, train_y = shuffle(train_x, train_y)

    classifier = MultinomialNB()
    train(train_x, train_y, v, classifier)

    print("Multinomial Naive Bayes Classifier")
    test(test_x, test_y, v, classifier)
    return classifier, conversion


def dt_main(dataset, v):
    if dataset == "BBC News":
        train_x, train_y, test_x, test_y, conversion = build_sets_bbc()
    elif dataset == "Huffington Post [1 million]":
        train_x, train_y, test_x, test_y, conversion = build_sets_huff()
    else:
        print(f"d err: {dataset}")
        return 

    train_x, train_y = shuffle(train_x, train_y)

    classifier = DecisionTreeClassifier()
    train(train_x, train_y, v, classifier)

    print("Decision Tree Classifer")
    test(test_x, test_y, v, classifier)
    return classifier, conversion

def rnn_main(dataset, v):
    if dataset == "BBC News":
        train_x, train_y, test_x, test_y, conversion = build_sets_bbc()
    elif dataset == "Huffington Post [1 million]":
        train_x, train_y, test_x, test_y, conversion = build_sets_huff()
    else:
        print(f"d err: {dataset}")
        return 

    train_x, train_y = shuffle(train_x, train_y)

    classifier = MLPClassifier(alpha=1, max_iter=100)
    train(train_x, train_y, v, classifier)

    print("RNN Classifier")
    test(test_x, test_y, v, classifier)
    return classifier, conversion

def knn_main(dataset, v):
    if dataset == "BBC News":
        train_x, train_y, test_x, test_y, conversion = build_sets_bbc()
    elif dataset == "Huffington Post [1 million]":
        train_x, train_y, test_x, test_y, conversion = build_sets_huff()
    else:
        print(f"d err: {dataset}")
        return 

    train_x, train_y = shuffle(train_x, train_y)

    classifier = KNeighborsClassifier(3)
    train(train_x, train_y, v, classifier)

    print("K Nearest Neighbors Classifier")
    test(test_x, test_y, v, classifier)
    return classifier, conversion

def rand_forest_main(dataset, v):
    if dataset == "BBC News":
        train_x, train_y, test_x, test_y, conversion = build_sets_bbc()
    elif dataset == "Huffington Post [1 million]":
        train_x, train_y, test_x, test_y, conversion = build_sets_huff()
    else:
        print(f"d err: {dataset}")
        return 

    train_x, train_y = shuffle(train_x, train_y)

    classifier = RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)
    train(train_x, train_y, v, classifier)

    print("Random Forest Classifier")
    test(test_x, test_y, v, classifier)
    return classifier, conversion

def train(x, y, v, classifier, lr = 1e-3, epochs=30):
    v.fit(x)
    x_train = v.transform(x)
    classifier.fit(x_train, y) 

def test(x, y, v, classifier):
    n = len(x)
    x_test = v.transform(x)
    y_pred = classifier.predict(x_test)
    # print("Accuracy:", metrics.accuracy_score(y, y_pred))

def shuffle(train_x, train_y):
    temp = list(zip(train_x, train_y))
    random.shuffle(temp)
    train_x, train_y = zip(*temp)
    return train_x, train_y

def build_sets_bbc(pivot = 0.2):
    categories = os.listdir("bbc/") 
    train_x, train_y, test_x, test_y = [], [], [], []
    conversion = {}
    for c, category in enumerate(categories):
        conversion[c] = category
        temp_path = "bbc/" + category + "/"
        articles = os.listdir(temp_path)
        random.shuffle(articles)
        n, i = pivot * len(articles), -1
        for article in articles:
            i += 1
            f = open(temp_path + article, encoding= 'unicode_escape')
            if i < n:
                test_x.append(f.read())
                test_y.append(c)
            else:
                train_x.append(f.read())
                train_y.append(c)
    return train_x, train_y, test_x, test_y, conversion

def build_sets_huff(pivot = 0.2):
    train_x, train_y, test_x, test_y = [], [], [], []
    df = pd.read_json('News_Category_Dataset_v3.json', lines=True)
    v = CountVectorizer()
    i2c = {}
    c2i = {}
    n, i = pivot * len(df.index), 0
    for index, row in df.iterrows():
        text = row['headline'] + row['short_description']
        c = row['category']
        if c in c2i:
            idx = c2i[c]
        else:
            idx = len(c2i.keys()) + 1
            c2i[c] = idx
            i2c[idx] = c
        
        if i < n:
            test_x.append(text)
            test_y.append(idx)
        else:
            train_x.append(text)
            train_y.append(idx)
        i += 1
    return train_x, train_y, test_x, test_y, i2c
    
if __name__ == "__main__":
    # main()
    demo()



'''
Dataset: BBC News, Vectorizer: CountVectorizer()

K Nearest Neighbors Classifier
Accuracy: 0.7544642857142857

Multinomial Naive Bayes Classifier
Accuracy: 0.9799107142857143

Random Forest Classifier
Accuracy: 0.27232142857142855

RNN Classifier
Accuracy: 0.9799107142857143

Decision Tree Classifer
Accuracy: 0.8125


Dataset: BBC News, Vectorizer: TfidfVectorizer()

K Nearest Neighbors Classifier
Accuracy: 0.9441964285714286

Multinomial Naive Bayes Classifier
Accuracy: 0.9375

Random Forest Classifier
Accuracy: 0.2611607142857143

RNN Classifier
Accuracy: 0.984375

Decision Tree Classifer
Accuracy: 0.828125


Dataset: Huffington Post [1 million], Vectorizer: CountVectorizer()

K Nearest Neighbors Classifier
Accuracy: 0.14711497160311174

Multinomial Naive Bayes Classifier
Accuracy: 0.45907507278194054

Random Forest Classifier
Accuracy: 0.34818403092635897


Dataset: Huffington Post [1 million], Vectorizer: TfidfVectorizer()

K Nearest Neighbors Classifier
Accuracy: 0.13556531284302964

Multinomial Naive Bayes Classifier
Accuracy: 0.4193910179926502

Random Forest Classifier
Accuracy: 0.3486135636901637
'''
